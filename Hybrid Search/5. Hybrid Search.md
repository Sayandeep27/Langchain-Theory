# Hybrid Search in RAG 

---

# 1. Why Hybrid Search is Needed in RAG

## Problem with Basic RAG (Vector Search Only)

Standard RAG pipeline:

```
User Query → Embedding → Vector DB → Similar Chunks → LLM
```

Vector databases use **semantic similarity**.

Example:

Query:

```
"How to reduce GPU memory usage?"
```

Vector search finds semantically similar chunks even if wording differs.

### Good at:

* Meaning understanding
* Synonyms
* Concept similarity

### Bad at:

* Exact keywords
* IDs, numbers, codes
* Rare terms
* Names

Example failure:

Query:

```
Error code: CUDA_9032
```

Embedding models may ignore this exact token.

Result → WRONG retrieval.

---

## Problem with Keyword Search (BM25)

Keyword search (BM25):

```
Query → keyword matching → ranked documents
```

### Good at:

* Exact matches
* Technical terms
* Error codes
* Names

### Bad at:

* Meaning understanding
* Synonyms
* Natural language queries

---

## The Core Insight

Vector Search answers:

> "What means the same?"

Keyword Search answers:

> "What contains the same words?"

**Hybrid Search = Combine BOTH**

---

# 2. What is Hybrid Search in RAG?

## Definition

Hybrid search combines:

* **Dense Retrieval** (Embeddings / Vector similarity)
* **Sparse Retrieval** (BM25 / keyword scoring)

To retrieve better context for the LLM.

---

## Conceptual Diagram

```
                    ┌──────────────┐
User Query ───────► │ Hybrid Search│
                    └──────┬───────┘
                           │
        ┌──────────────────┴──────────────────┐
        │                                     │
 Dense Search                           Sparse Search
 (Embeddings)                           (BM25)
        │                                     │
 Semantic Score                        Keyword Score
        └──────────────┬──────────────────────┘
                       ↓
                 Score Fusion
                       ↓
                Top-K Documents
                       ↓
                      LLM
```

---

# 3. Dense vs Sparse Retrieval (Deep Understanding)

## A. Dense Retrieval (Vector Search)

Each document → embedding vector.

Similarity:

```
cosine_similarity(query_vector, doc_vector)
```

Captures:

* semantics
* context
* intent

Example:

```
"car" ≈ "automobile"
```

---

## B. Sparse Retrieval (BM25)

BM25 scoring formula (simplified):

```
Score(D,Q) = Σ IDF(q_i) * ( f(q_i,D)(k+1) / ( f(q_i,D)+k(1-b+b|D|/avgdl) ) )
```

Where:

* `f(q_i,D)` = term frequency
* `IDF` = importance of word
* penalizes long documents

Captures:

* exact tokens
* frequency importance

---

# 4. How Hybrid Search Works (Step-by-Step)

## Step 1 — User Query

```
"What is LangChain retriever?"
```

---

## Step 2 — Two Parallel Searches

### Dense Search

```
embedding(query)
→ vector similarity
```

Returns semantically related docs.

---

### Sparse Search

```
BM25(query)
```

Returns keyword matches.

---

## Step 3 — Score Fusion

Combine scores using:

### Method 1: Weighted Sum

```
Final Score =
α * Dense Score +
(1-α) * Sparse Score
```

Example:

```
α = 0.7
```

Meaning semantic search is more important.

---

### Method 2: Reciprocal Rank Fusion (RRF) (VERY popular)

```
RRF = Σ 1/(k + rank)
```

Advantages:

* No score normalization needed
* Works extremely well in practice

Used in:

* RAG Fusion
* Modern retrieval systems

---

## Step 4 — Select Top-K Documents

Best combined results go to LLM.

---

# 5. Why Hybrid Search Improves RAG (Key Benefits)

| Problem                       | Hybrid Solution            |
| ----------------------------- | -------------------------- |
| Embeddings miss keywords      | BM25 catches them          |
| Keyword search misses meaning | Embeddings capture meaning |
| Hallucinations                | Better grounding           |
| Low recall                    | Higher recall              |
| Technical docs                | Much better retrieval      |

---

# 6. Example Comparison

Query:

```
"FlashRank reranker parameters"
```

| Method      | Result                     |
| ----------- | -------------------------- |
| Vector only | General reranking docs     |
| BM25 only   | Exact mentions only        |
| Hybrid      | Exact + conceptual matches |

Hybrid gives best context → better LLM answer.

---

# 7. Hybrid Search Architectures in RAG

## Architecture 1 — Parallel Hybrid (Most Common)

```
Query
 ├─ BM25 Retriever
 └─ Vector Retriever
      ↓
   Fusion
```

Used in:

* LangChain
* LlamaIndex
* Pinecone hybrid
* Weaviate hybrid

---

## Architecture 2 — Dense → Sparse Rerank

```
Vector search → candidates → BM25 rerank
```

---

## Architecture 3 — Sparse → Dense Rerank

```
BM25 → candidates → embedding rerank
```

---

# 8. Hybrid Search in Popular Vector Databases

| Database      | Hybrid Support  |
| ------------- | --------------- |
| Pinecone      | Native hybrid   |
| Weaviate      | Native hybrid   |
| Elasticsearch | BM25 + vectors  |
| OpenSearch    | Hybrid ranking  |
| Qdrant        | Sparse + dense  |
| Vespa         | Advanced hybrid |

---

# 9. Hybrid Search Implementation (LangChain Example)

## Step 1 — Install

```bash
pip install rank_bm25 faiss-cpu sentence-transformers
```

---

## Step 2 — Dense Retriever

```python
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings

embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)

vector_db = FAISS.from_documents(docs, embeddings)
dense_retriever = vector_db.as_retriever(search_kwargs={"k":5})
```

---

## Step 3 — Sparse Retriever (BM25)

```python
from langchain.retrievers import BM25Retriever

bm25_retriever = BM25Retriever.from_documents(docs)
bm25_retriever.k = 5
```

---

## Step 4 — Ensemble Retriever (Hybrid)

```python
from langchain.retrievers import EnsembleRetriever

hybrid_retriever = EnsembleRetriever(
    retrievers=[bm25_retriever, dense_retriever],
    weights=[0.5, 0.5]
)
```

---

## Step 5 — Use in RAG

```python
docs = hybrid_retriever.get_relevant_documents(query)
```

Now retrieval is hybrid.

---

# 10. Advanced Hybrid Improvements (Modern RAG)

Hybrid search is often combined with:

### 1. Rerankers (BEST PRACTICE)

```
Hybrid → Cross Encoder Reranker → LLM
```

Example:

* FlashRank
* Cohere rerank
* bge-reranker

---

### 2. Query Expansion

LLM generates multiple queries:

```
Original query
+ variations
→ hybrid search
```

(RAG Fusion)

---

### 3. Adaptive Hybrid Weighting

Dynamic α value:

```
technical query → more BM25
semantic query → more embeddings
```

---

# 11. When Should You Use Hybrid Search?

Use hybrid when:

* PDFs
* Documentation QA
* Codebases
* Technical manuals
* Enterprise search
* RAG chatbots
* Error/debug assistants

Basically:

**90% of production RAG systems use hybrid retrieval today.**

---

# 12. Hybrid vs Vector vs BM25 (Final Intuition)

Think of search like detectives:

| Search Type | Detective Style       |
| ----------- | --------------------- |
| BM25        | Looks for exact words |
| Vector      | Understands meaning   |
| Hybrid      | Uses BOTH brains      |

---

# 13. Real Production RAG Pipeline (Modern)

```
User Query
     ↓
Query Rewrite (LLM)
     ↓
HYBRID RETRIEVAL
(Dense + Sparse)
     ↓
Reranker
     ↓
Context Compression
     ↓
LLM Generation
```

This is **state-of-the-art RAG**.

---

## Final One-Line Understanding

**Hybrid Search in RAG combines semantic similarity (embeddings) and keyword matching (BM25) to retrieve more accurate and complete context, dramatically improving LLM answer quality.**

---

**End of README**
